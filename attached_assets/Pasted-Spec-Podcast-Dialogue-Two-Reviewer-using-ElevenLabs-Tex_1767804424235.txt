Spec: “Podcast Dialogue” (Two-Reviewer) using ElevenLabs Text-to-Dialogue (v3)
1) Goal

Turn two existing reviewer reports (already generated by Gemini) into a podcast-like dialogue (two voices), rendered as a single audio asset using ElevenLabs Text to Dialogue (Eleven v3).

Scope v1: exactly two reviewers in one dialogue episode

Episode length target: ~4–6 minutes (configurable later)

Language-aware: output language must match the session/report language (e.g., en, zh-TW)

2) Non-goals (v1)

No 3–4 person group conversations

No real-time streaming playback from partial dialogue generation (generate then play)

No user editing of the script in UI (v1 can show transcript read-only)

3) Inputs & Preconditions
3.1 Preconditions

User has already run analysis and has ≥ 2 persona reports for the same screening session.

Each report is the existing JSON schema:

executive_summary

highlights[5]

concerns[5]

answers[]

3.2 Inputs to “Podcast Dialogue” job

sessionId

language (must match the report language)

reviewerA: personaId

reviewerB: personaId

reportsByPersonaId: { [personaId]: PersonaReportJSON }

voiceMap: { [personaId]: { voiceId: string } } (Eleven voice IDs)

4) Output Artifacts

For each generated episode:

dialogue_script.json
A deterministic structure of turns (speakers + text + references) for debugging and audit.

dialogue_audio.(mp3|wav) (single file)
Returned from ElevenLabs Text-to-Dialogue endpoint.

dialogue_transcript.txt (optional)
Plain transcript for UI display (can be derived from script).

5) High-level Architecture (Pipeline)
Step 0 — Validate

Confirm both reports exist and are complete (5 highlights, 5 concerns).

Confirm language is known and supported by selected voices.

Step 1 — Generate “Dialogue Script” (LLM)

Use an LLM (Gemini or your existing stack) to transform the two reports into a two-person conversation.

Output format (required):

type DialogueScript = {
  version: "1.0";
  sessionId: number | string;
  language: "en" | "zh-TW";
  participants: Array<{
    personaId: string;
    displayName: string; // "Sarah Chen"
    role: string;        // "Senior Acquisitions Director"
    voiceId: string;     // ElevenLabs voiceId
  }>;
  runtimeTargetSec: number; // e.g. 300
  turns: Array<{
    speakerPersonaId: string;
    text: string; // single utterance, 1–3 sentences max
    refs?: Array<{
      personaId: string;
      type: "highlight" | "concern" | "answer" | "summary";
      index?: number;
      timestamp?: string;
      seconds?: number;
    }>;
    audioTag?: string; // optional; e.g. "thoughtfully"
  }>;
  coverage: {
    byPersona: Record<string, { highlights: boolean[]; concerns: boolean[]; answers: boolean[] }>;
  };
};


Hard constraints for script generation

Must be natural conversation, not “reading bullet points”

Must cover all highlights/concerns from both reviewers

No new plot events, no new timestamps (only reference what’s in reports)

No timestamp-first sentences (timestamps can appear mid-sentence)

Keep each turn short (1–3 sentences)

Allow disagreement and contrast, but remain constructive/professional

Step 2 — Inject Minimal v3 “Audio Tags”

Eleven v3 supports square-bracket tags to shape delivery. Use sparingly. 
ElevenLabs
+1

Rule: ≤ 1 tag per 3 turns; do not tag every line.

Examples:

“thoughtfully”

“warmly”

“seriously”

“laughs softly” (use carefully)

Represent tags in audioTag, then render as [tag] prefix in the final text.

Step 3 — Call ElevenLabs Text-to-Dialogue API

Use the official Text-to-Dialogue “convert” endpoint. 
ElevenLabs
+1

Request payload concept

Provide an ordered list of dialogue inputs (turns), each containing:

text

voice_id (persona voice)

Use Eleven v3 model / dialogue mode where applicable (per Eleven’s Text-to-Dialogue docs). 
ElevenLabs
+1

Note on v3 prompting

v3 can be inconsistent with very short prompts; Eleven recommends prompts > 250 characters for better consistency. 
ElevenLabs

In this context, your “prompt” is effectively the overall script—so ensure the script has enough context and isn’t overly fragmented.

Step 4 — Store and Serve

Persist:

dialogue_script.json (debuggable truth)

audioUrl (or blob storage key)

metadata: voices, model_id, timestamps, duration, generation attempt count

6) Reliability Strategy (Recommended)

Eleven’s own guidance implies you may need multiple generations to get best results for dialogue-style outputs. 
ElevenLabs
+1

v1 approach (simple)

Generate script once

Generate audio once

If fail: retry once automatically

v1.5 approach (quality)

Generate 2 scripts (same constraints, different “conversation style seeds”)

Render both audio

Pick:

either by quick user selection (“Version A / Version B”)

or by an internal judge heuristic:

penalize “report reading”

require coverage completeness

7) UI Spec: Two-Reviewer Selector + Episode Player
7.1 Entry point

In ScreeningRoom (or a “Dialogue” tab), show a module:

Title: Podcast Dialogue (Beta)
Body: “Pick two reviewers to generate a post-screening conversation.”

7.2 Reviewer availability logic

If user has only 1 reviewer report: show disabled state + helper text “Generate at least one more reviewer report to create a dialogue.”

If 2–4 reports exist: allow choosing any two.

7.3 Interaction design

Component: ReviewerPairPicker

List all available reviewers with:

avatar

name + role

a badge indicating “Report ready”

Selection behavior:

user can select up to 2

selecting a third replaces the oldest selection (or block with tooltip; pick one pattern and stick to it)

Primary CTA

Disabled until exactly 2 selected

Label:

EN: “Generate dialogue”

zh-TW: “產生對談”

Secondary controls

“Swap speakers” (swap A/B for voice order)

“Preview transcript only” (optional v1; still generates script but skips audio)

7.4 Dialogue generation state UI

When generating:

Show progress steps:

“Drafting conversation…”

“Rendering audio…”

“Finalizing…”

7.5 Playback UI

Once audio ready:

Audio player with:

Play/pause

scrubber

duration

Transcript panel (collapsible):

show turns with speaker labels

timestamps shown only if present (and never as leading tokens in the transcript UI)

“Regenerate” button (re-run pipeline)

“Download” button (optional)

8) Backend API Changes (Recommended)
8.1 New endpoints

POST /api/dialogue/create

Body:

{
  "sessionId": 123,
  "language": "zh-TW",
  "personaIdA": "acquisitions_director",
  "personaIdB": "cultural_editor"
}


Response immediately with jobId

GET /api/dialogue/status/:jobId

Returns:

queued | scripting | rendering | complete | failed

progress metadata

GET /api/dialogue/result/:jobId

Returns:

audio URL

script JSON (optional)

transcript

This mirrors your existing job-based approach for upload/analyze and avoids blocking the UI.

8.2 Storage fields (DB)

dialogue_job

id, sessionId

personaA, personaB

language

status

scriptJson

audioStorageKey / audioUrl

createdAt, updatedAt

attemptCount, lastError

9) Script Generation Prompt (LLM) — Requirements to bake in

Key constraints you must include in the prompt:

Must feel like a real discussion, not a memo

No turn starts with timestamps (e.g., “在 02:13…”)

No invented scenes/events

Must include ALL 10 points from each reviewer (or at minimum: all highlights+concerns; answers optional but recommended)

Use Taiwan Mandarin when zh-TW

Include light disagreement and callbacks (“我同意你說的那段…但…”)

10) ElevenLabs Integration Notes
10.1 Endpoint

Use Text-to-Dialogue “convert” endpoint with list-of-text+voice inputs. 
ElevenLabs

10.2 Audio tags

v3 supports bracket tags that affect delivery without being spoken. 
ElevenLabs
+1

Use tags sparingly; section-level only.

10.3 v3 prompt length best practice

Very short prompts are more inconsistent; prefer longer context. 
ElevenLabs

Practical implication: avoid ultra-short turns; merge where needed into 1–2 sentence turns with sufficient context.

11) Acceptance Criteria (Definition of Done)

UI allows selecting exactly two reviewers from available reports.

“Generate dialogue” creates a background job; UI shows progress and doesn’t block.

Generated dialogue:

alternates speakers naturally

covers all highlights/concerns for both personas

no invented timestamps or new plot events

language correct (en or zh-TW)

Audio file plays successfully in-app.

Transcript is displayed and matches the audio script.

12) Recommended MVP defaults

runtimeTargetSec: 300 (5 minutes)

tags: minimal (1 per section)

retries: 1 auto retry on Eleven failure

cache key: (sessionId, personaA, personaB, language, reportsHash)